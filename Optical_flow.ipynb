{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "\n",
    "Submitted by: [*name and ID*]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sparse optical flow\n",
    "\n",
    "In this part you will calculate and visualize optical flow on a live video feed from a webcam.\n",
    "\n",
    "First, find some good features to track, use either Harris corners, or Shi-Tomasi corners (`cv2.goodFeaturesToTrack`).\n",
    "\n",
    "Then, you will track these features from frame to frame, and display their location on the live video feed. Use: `cv2.calcOpticalFlowPyrLK`.\n",
    "\n",
    "As features tend to get lost during the time (check their returned status), it is advised to look for new features to track, from time to time (either every N frames, or when the features number falls below some level).\n",
    "\n",
    "Try to add a visual trace of the motion. See for example: https://www.youtube.com/watch?v=E86NLzNbuL8\n",
    "\n",
    "\n",
    "- API doc: https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html\n",
    "\n",
    "- Example: http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners =100,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 3,\n",
    "                       blockSize = 10 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (20,20),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "#p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if ret:\n",
    "            p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "            # calculate optical flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "            if len(p1)>0:\n",
    "                \n",
    "                # Select good points\n",
    "                good_new = p1[st==1]\n",
    "                good_old = p0[st==1]\n",
    "                #print(len(good_new),len(good_old))\n",
    "                # Create a mask image for drawing purposes\n",
    "                mask = np.zeros_like(old_frame)\n",
    "\n",
    "                # draw the tracks\n",
    "                for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "                    a,b = new.ravel()\n",
    "                    c,d = old.ravel()\n",
    "                    mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "                    frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "                img = cv2.add(frame,mask)\n",
    "            \n",
    "                \n",
    "        cv2.imshow('frame',img)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        # Now update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "except:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive tracking\n",
    "\n",
    "In this part, we will add some interactive aspects to your previous implementation. \n",
    "\n",
    "First, the live video is shown without any features. \n",
    "\n",
    "Then, the user draws a region-of-interest (ROI) box on the video. Only the features that fall inside this region should be tracked from frame to frame. \n",
    "\n",
    "In every frame, plot the bounding box of the tracked features (using cv2.boundingRect).\n",
    "\n",
    "Once again, since features tend to get lost over time, find some new features to track every now and then.\n",
    "\n",
    "See for example: https://www.youtube.com/watch?v=kcrGkD2HOZs\n",
    "\n",
    "Tutorial on handling mouse events in OpenCV: \n",
    "- http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_mouse_handling/py_mouse_handling.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_flow(image_clone,frame):\n",
    "\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners =100,\n",
    "                           qualityLevel = 0.1,\n",
    "                           minDistance = 3,\n",
    "                           blockSize = 10 )\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (20,20),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "    # Take first frame and find corners in it\n",
    "    #ret, old_frame = cap.read()\n",
    "    old_frame= image_clone\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    #p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if ret:\n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "        if len(p1)>0:\n",
    "\n",
    "            # Select good points\n",
    "            good_new = p1[st==1]\n",
    "            good_old = p0[st==1]\n",
    "            #print(len(good_new),len(good_old))\n",
    "            # Create a mask image for drawing purposes\n",
    "            mask = np.zeros_like(old_frame)\n",
    "\n",
    "            # draw the tracks\n",
    "            for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "                a,b = new.ravel()\n",
    "                c,d = old.ravel()\n",
    "                mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "                frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "            img = cv2.add(frame,mask)\n",
    "\n",
    "\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7a2617509b56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaitTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rect = (0,0,0,0)\n",
    "startPoint = False\n",
    "endPoint = False\n",
    "def on_mouse(event,x,y,flags,params):\n",
    "\n",
    "    global rect,startPoint,endPoint\n",
    "\n",
    "    # get mouse click\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    " \n",
    "        if startPoint == True and endPoint == True:\n",
    "            startPoint = False\n",
    "            endPoint = False\n",
    "            rect = (0, 0, 0, 0)\n",
    "\n",
    "        if startPoint == False:\n",
    "            rect = (x, y, 0, 0)\n",
    "            startPoint = True\n",
    "        elif endPoint == False:\n",
    "            rect = (rect[0], rect[1], x, y)\n",
    "            endPoint = True\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "waitTime = 50\n",
    "\n",
    "#Reading the first frame\n",
    "(grabbed, frame) = cap.read()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    (grabbed, frame) = cap.read()\n",
    "\n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.setMouseCallback('frame', on_mouse)    \n",
    "\n",
    "    #drawing rectangle\n",
    "    if startPoint == True and endPoint == True:\n",
    "        x = rect[0]\n",
    "        y = rect[1]\n",
    "        w = rect[2]\n",
    "        h = rect[3]\n",
    "        #print(x,y,h,w)\n",
    "        cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (255, 0, 255), 2)\n",
    "        roi = frame[y:h,x:w]\n",
    "        clone = roi.copy()\n",
    "        imc = optical_flow(clone,roi)\n",
    "        \n",
    "        \n",
    "        #cv2.imshow('c',imc)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    key = cv2.waitKey(waitTime) \n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
